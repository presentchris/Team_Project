{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cec81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2dcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfd_folder_path = 'skindata/train/forehead/dry'\n",
    "Xnd_folder_path = 'skindata/train/nose/dry'\n",
    "Xcd_folder_path = 'skindata/train/cheek/dry'\n",
    "Xfo_folder_path = 'skindata/train/forehead/oily'\n",
    "Xno_folder_path = 'skindata/train/nose/oily'\n",
    "Xco_folder_path = 'skindata/train/cheek/oily'\n",
    "yfd_folder_path = 'skindata/test/forehead/dry'\n",
    "ynd_folder_path = 'skindata/test/nose/dry'\n",
    "ycd_folder_path = 'skindata/test/cheek/dry'\n",
    "yfo_folder_path = 'skindata/test/forehead/oily'\n",
    "yno_folder_path = 'skindata/test/nose/oily'\n",
    "yco_folder_path = 'skindata/test/cheek/oily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78dd92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 이미지 크기를 일괄 조정하는 함수\n",
    "# def resize_and_save_images(input_folder, output_folder, target_size=(128, 128)):\n",
    "#     # 폴더 내의 파일 목록을 얻습니다.\n",
    "#     file_list = os.listdir(input_folder)\n",
    "\n",
    "#     # 출력 폴더가 없다면 생성합니다.\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     # 각 파일에 대해 이미지 크기를 일괄 조정합니다.\n",
    "#     for file_name in file_list:\n",
    "#         file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "#         # 이미지 읽기\n",
    "#         img = cv2.imread(file_path)\n",
    "\n",
    "#         # 이미지가 올바로 읽혔는지 확인\n",
    "#         if img is None:\n",
    "#             print(f\"Error: Unable to read the image at {file_path}\")\n",
    "#             continue\n",
    "\n",
    "#         # 이미지 크기 조정\n",
    "#         resized_img = cv2.resize(img, target_size)\n",
    "\n",
    "#         # 크기가 조정된 이미지를 저장할 경로\n",
    "#         save_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "#         # 크기가 조정된 이미지 저장\n",
    "#         cv2.imwrite(save_path, resized_img)\n",
    "\n",
    "# # 리사이즈할 폴더와 저장할 폴더 경로 설정\n",
    "# input_train_folder = 'skindata/train'\n",
    "# output_train_folder = 'resized_train'\n",
    "\n",
    "# input_test_folder = 'skindata/test'\n",
    "# output_test_folder = 'resized_test'\n",
    "\n",
    "# # 각 얼굴 부위에 대한 훈련 데이터셋 리사이즈\n",
    "# resize_and_save_images(Xfd_folder_path, os.path.join(output_train_folder, 'forehead/dry'))\n",
    "# resize_and_save_images(Xnd_folder_path, os.path.join(output_train_folder, 'nose/dry'))\n",
    "# resize_and_save_images(Xcd_folder_path, os.path.join(output_train_folder, 'cheek/dry'))\n",
    "# resize_and_save_images(Xfo_folder_path, os.path.join(output_train_folder, 'forehead/oily'))\n",
    "# resize_and_save_images(Xno_folder_path, os.path.join(output_train_folder, 'nose/oily'))\n",
    "# resize_and_save_images(Xco_folder_path, os.path.join(output_train_folder, 'cheek/oily'))\n",
    "\n",
    "# # 각 얼굴 부위에 대한 테스트 데이터셋 리사이즈\n",
    "# resize_and_save_images(yfd_folder_path, os.path.join(output_test_folder, 'forehead/dry'))\n",
    "# resize_and_save_images(ynd_folder_path, os.path.join(output_test_folder, 'nose/dry'))\n",
    "# resize_and_save_images(ycd_folder_path, os.path.join(output_test_folder, 'cheek/dry'))\n",
    "# resize_and_save_images(yfo_folder_path, os.path.join(output_test_folder, 'forehead/oily'))\n",
    "# resize_and_save_images(yno_folder_path, os.path.join(output_test_folder, 'nose/oily'))\n",
    "# resize_and_save_images(yco_folder_path, os.path.join(output_test_folder, 'cheek/oily'))\n",
    "\n",
    "# # 리사이즈된 이미지를 읽어오고 확인하는 코드\n",
    "# # 예시로 하나의 이미지만 확인\n",
    "# sample_resized_image_path = os.path.join(output_train_folder, 'forehead/dry', os.listdir(os.path.join(output_train_folder, 'forehead/dry'))[0])\n",
    "# sample_resized_image = cv2.imread(sample_resized_image_path)\n",
    "\n",
    "# # 이미지가 올바로 읽혔는지 확인\n",
    "# if sample_resized_image is not None:\n",
    "#     # 이미지를 화면에 출력\n",
    "#     cv2.imshow('Sample Resized Image', sample_resized_image)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "# else:\n",
    "#     print(f\"Error: Unable to read the resized image at {sample_resized_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7450ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 픽셀 값을 [0, 1] 범위로 스케일링하는 함수\n",
    "# def preprocess_input(image):\n",
    "#     return image / 255.0\n",
    "\n",
    "# # 세그멘테이션 모델 로드 또는 훈련\n",
    "# # 여기에서는 가상의 모델로 대체합니다. 실제로는 훈련된 모델을 로드하거나 적절한 세그멘테이션 모델을 사용해야 합니다.\n",
    "# def load_segmentation_model():\n",
    "#     # 가상의 모델을 반환합니다.\n",
    "#     # 실제로는 모델을 로드하거나 훈련하는 코드로 대체해야 합니다.\n",
    "#     return SomeSegmentationModel()\n",
    "\n",
    "# class SomeSegmentationModel:\n",
    "#     def predict(self, input_data):\n",
    "#         # 가상의 predict 메서드\n",
    "#         # 실제로는 입력 데이터에 대해 세그멘테이션을 수행하는 코드로 대체해야 합니다.\n",
    "#         return np.ones_like(input_data)\n",
    "\n",
    "# # 세그멘테이션 모델을 사용하여 이미지 세그멘테이션 수행\n",
    "# segmentation_model = load_segmentation_model()  # 실제 모델을 로드하거나 훈련하는 코드로 대체\n",
    "\n",
    "# # 데이터 경로 설정\n",
    "# base_path = 'resized_skindata'\n",
    "# save_path_segmented = 'segmented_skindata'\n",
    "\n",
    "# # 얼굴 부위 및 피부 상태 설정\n",
    "# face_parts = ['cheek', 'forehead', 'nose']\n",
    "# skin_states = ['dry', 'oily']\n",
    "\n",
    "# # 이미지 세그멘테이션 및 윤곽선 저장\n",
    "# for state in skin_states:\n",
    "#     for part in face_parts:\n",
    "#         for data_split in ['resized_train', 'resized_test']:\n",
    "#             folder_path = os.path.join(base_path, data_split, part, state)\n",
    "#             save_path_segmented_part = os.path.join(save_path_segmented, data_split, part, state)\n",
    "#             os.makedirs(save_path_segmented_part, exist_ok=True)\n",
    "\n",
    "#             for filename in os.listdir(folder_path):\n",
    "#                 img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "#                 # 이미지를 세그멘테이션하기 위해 위에서 작성한 코드 사용\n",
    "#                 image_to_segment = cv2.imread(img_path)\n",
    "#                 image_to_segment = cv2.cvtColor(image_to_segment, cv2.COLOR_BGR2RGB)\n",
    "#                 image_to_segment = cv2.resize(image_to_segment, (128, 128))\n",
    "\n",
    "#                 segmentation_mask = segmentation_model.predict(np.expand_dims(preprocess_input(image_to_segment), axis=0))[0]\n",
    "#                 segmented_image = image_to_segment * segmentation_mask\n",
    "#                 segmented_image = cv2.resize(segmented_image, (128, 128))\n",
    "#                 segmented_image = preprocess_input(segmented_image)\n",
    "\n",
    "#                 # 저장 경로 설정\n",
    "#                 save_path = os.path.join(save_path_segmented_part, filename)\n",
    "\n",
    "#                 # 이미지 저장\n",
    "#                 cv2.imwrite(save_path, (segmented_image * 255).astype(np.uint8))\n",
    "\n",
    "#                 # 윤곽선을 찾기 위한 코드\n",
    "#                 dst_img = image_to_segment.copy()\n",
    "\n",
    "#                 # 각 채널에 대해 윤곽선을 찾습니다.\n",
    "#                 for i in range(3):  # 3개의 채널(BGR)에 대해 반복\n",
    "#                     channel = image_to_segment[:, :, i]  # 각 채널 선택\n",
    "#                     ret, otsu = cv2.threshold(channel, -1, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#                     contours, hier = cv2.findContours(otsu, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#                     COLOR = (0, 200, 2)\n",
    "#                     cv2.drawContours(dst_img, contours, -1, COLOR, 2)\n",
    "\n",
    "#                 # 윤곽선을 저장할 경로 설정\n",
    "#                 save_path_contours = os.path.join(save_path_segmented_part, 'contours', filename)\n",
    "#                 os.makedirs(os.path.dirname(save_path_contours), exist_ok=True)\n",
    "\n",
    "#                 # 윤곽선 저장\n",
    "#                 cv2.imwrite(save_path_contours, dst_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545032d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "base_path = 'segmented_skindata'\n",
    "\n",
    "# 얼굴 부위 및 피부 상태 설정\n",
    "face_parts = ['forehead', 'nose', 'cheek']\n",
    "skin_states = ['dry', 'oily']\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for state in skin_states:\n",
    "    for part in face_parts:\n",
    "        folder_path = os.path.join(base_path, 'resized_train', part, state)\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Additional check to skip empty images\n",
    "            if os.path.isfile(img_path):\n",
    "                img = cv2.imread(img_path)\n",
    "\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (128, 128))\n",
    "\n",
    "                    data.append(img)\n",
    "                    labels.append(f'{part}_{state}') \n",
    "                else:\n",
    "                    print(f\"Warning: Unable to read the image at {img_path}\")\n",
    "\n",
    "\n",
    "# 데이터와 레이블을 numpy 배열로 변환\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "encoded_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# 데이터 분할 (8:2 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70280c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 79s 4s/step - loss: 1.2595 - accuracy: 0.4740 - val_loss: 1.1108 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 63s 4s/step - loss: 0.4465 - accuracy: 0.8368 - val_loss: 0.8358 - val_accuracy: 0.6319\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 55s 3s/step - loss: 0.1995 - accuracy: 0.9358 - val_loss: 1.2202 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 72s 4s/step - loss: 0.1561 - accuracy: 0.9323 - val_loss: 1.7162 - val_accuracy: 0.6319\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 73s 4s/step - loss: 0.1360 - accuracy: 0.9566 - val_loss: 2.1080 - val_accuracy: 0.5417\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 68s 4s/step - loss: 0.1717 - accuracy: 0.9410 - val_loss: 2.4735 - val_accuracy: 0.5278\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 74s 4s/step - loss: 0.1990 - accuracy: 0.9340 - val_loss: 2.3915 - val_accuracy: 0.5972\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 63s 4s/step - loss: 0.1739 - accuracy: 0.9253 - val_loss: 1.8615 - val_accuracy: 0.6111\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.1429 - accuracy: 0.9566 - val_loss: 1.3108 - val_accuracy: 0.6736\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 81s 5s/step - loss: 0.0896 - accuracy: 0.9670 - val_loss: 2.0480 - val_accuracy: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a8e34d9a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128,128, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d715048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 756ms/step - loss: 2.0480 - accuracy: 0.5833\n",
      "Test Loss: 2.0479650497436523, Test Accuracy: 0.5833333134651184\n",
      "Actual: cheek_dry, Predicted: cheek_dry\n",
      "Actual: cheek_dry, Predicted: cheek_dry\n",
      "Actual: forehead_dry, Predicted: forehead_dry\n",
      "Actual: nose_dry, Predicted: cheek_oily\n",
      "Actual: forehead_oily, Predicted: forehead_oily\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 예측 결과 출력\n",
    "for i in range(5):  # 예측 결과 중에서 처음 5개만 출력\n",
    "    predicted_class = label_encoder.classes_[np.argmax(predictions[i])]\n",
    "    actual_class = label_encoder.classes_[np.argmax(y_test[i])]\n",
    "    print(f'Actual: {actual_class}, Predicted: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276f095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
